{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ad666e6",
   "metadata": {
    "cellId": "9hpa8obooohpwpdlje9nad"
   },
   "source": [
    "# Эксперименты на датасете Ta-Feng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8ca700",
   "metadata": {
    "cellId": "uaw0zpsw7h49nfupczxdk"
   },
   "source": [
    "Все эксперименты были запущены на NVIDIA Tesla V100 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dcd9046b",
   "metadata": {
    "cellId": "1teuk4fdbn8igxpevhy7b"
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4716d4bf",
   "metadata": {
    "cellId": "kf5n731geofii3a5oqoh7p"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import logging\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from helpers import *\n",
    "from models.general import *\n",
    "from models.sequential import *\n",
    "from models.developing import *\n",
    "from utils import utils\n",
    "\n",
    "def parse_global_args(parser):\n",
    "    parser.add_argument('--gpu', type=str, default='0',\n",
    "                        help='Set CUDA_VISIBLE_DEVICES')\n",
    "    parser.add_argument('--verbose', type=int, default=logging.INFO,\n",
    "                        help='Logging Level, 0, 10, ..., 50')\n",
    "    parser.add_argument('--log_file', type=str, default='',\n",
    "                        help='Logging file path')\n",
    "    parser.add_argument('--random_seed', type=int, default=0,\n",
    "                        help='Random seed of numpy and pytorch.')\n",
    "    parser.add_argument('--load', type=int, default=0,\n",
    "                        help='Whether load model and continue to train')\n",
    "    parser.add_argument('--train', type=int, default=1,\n",
    "                        help='To train the model or not.')\n",
    "    parser.add_argument('--regenerate', type=int, default=0,\n",
    "                        help='Whether to regenerate intermediate files.')\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b1d74c7",
   "metadata": {
    "cellId": "nkf5566tlz9jh1e4pyde7"
   },
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "\n",
    "    init_parser = argparse.ArgumentParser(description='Model')\n",
    "    init_parser.add_argument('--model_name', \n",
    "                             type=str, \n",
    "                             default=MODEL_NAME, # 'BPR'\n",
    "                             help='Choose a model to run.')\n",
    "    init_parser.add_argument('--dataset', \n",
    "                             type=str, \n",
    "                             default=DATASET, # 'Gourmet'\n",
    "                             help='Choose a dataset to run.')\n",
    "    \n",
    "    init_args, init_extras = init_parser.parse_known_args()\n",
    "\n",
    "    model_name = eval('{0}.{0}'.format(MODEL_NAME))\n",
    "    reader_name = eval('{0}.{0}'.format(model_name.reader))\n",
    "    runner_name = eval('{0}.{0}'.format(model_name.runner))\n",
    "\n",
    "    # # Args\n",
    "    parser = argparse.ArgumentParser(description='')\n",
    "    parser = parse_global_args(parser)\n",
    "    parser = reader_name.parse_data_args(parser)\n",
    "    parser = runner_name.parse_runner_args(parser)\n",
    "    parser = model_name.parse_model_args(parser)\n",
    "    args, extras = parser.parse_known_args()\n",
    "\n",
    "    # Logging configuration\n",
    "    log_args = [init_args.model_name, init_args.dataset, str(RANDOM_SEED), str(POOLING)]\n",
    "    for arg in ['lr', 'l2'] + model_name.extra_log_args:\n",
    "        log_args.append(arg + '=' + str(eval('args.' + arg)))\n",
    "    log_file_name = '__'.join(log_args).replace(' ', '__') \n",
    "    if args.log_file == '':\n",
    "        args.log_file = '../log/{}/{}.txt'.format(init_args.model_name, log_file_name)\n",
    "    if args.model_path == '':\n",
    "        args.model_path = '../model/{}/{}.pt'.format(init_args.model_name, log_file_name)\n",
    "\n",
    "    utils.check_dir(args.log_file)\n",
    "    logging.basicConfig(filename=args.log_file, level=args.verbose)\n",
    "    logging.getLogger().addHandler(logging.StreamHandler(sys.stdout))\n",
    "    logging.info(init_args)\n",
    "    \n",
    "    return args\n",
    "\n",
    "\n",
    "def parse_args_kda():\n",
    "\n",
    "    init_parser = argparse.ArgumentParser(description='Model')\n",
    "    init_parser.add_argument('--model_name', \n",
    "                             type=str, \n",
    "                             default=MODEL_NAME, # 'BPR'\n",
    "                             help='Choose a model to run.')\n",
    "    init_parser.add_argument('--dataset', \n",
    "                             type=str, \n",
    "                             default=DATASET, # 'Gourmet'\n",
    "                             help='Choose a dataset to run.')\n",
    "    init_parser.add_argument('--rnn_model', \n",
    "                             type=str, \n",
    "                             default=RNN, # 'lstm'\n",
    "                             help='Choose a rnn to run.')\n",
    "    init_args, init_extras = init_parser.parse_known_args()\n",
    "\n",
    "    model_name = eval('{0}.{0}'.format(MODEL_NAME))\n",
    "    reader_name = eval('{0}.{0}'.format(model_name.reader))\n",
    "    runner_name = eval('{0}.{0}'.format(model_name.runner))\n",
    "\n",
    "    # # Args\n",
    "    parser = argparse.ArgumentParser(description='')\n",
    "    parser = parse_global_args(parser)\n",
    "    parser = reader_name.parse_data_args(parser)\n",
    "    parser = runner_name.parse_runner_args(parser)\n",
    "    parser = model_name.parse_model_args(parser)\n",
    "    args, extras = parser.parse_known_args()\n",
    "\n",
    "    # Logging configuration\n",
    "    log_args = [init_args.model_name, init_args.dataset, init_args.rnn_model, str(RANDOM_SEED), str(POOLING)]\n",
    "    for arg in ['lr', 'l2'] + model_name.extra_log_args:\n",
    "        log_args.append(arg + '=' + str(eval('args.' + arg)))\n",
    "    log_file_name = '__'.join(log_args).replace(' ', '__') \n",
    "    if args.log_file == '':\n",
    "        args.log_file = '../log/{}/{}.txt'.format(init_args.model_name, log_file_name)\n",
    "    if args.model_path == '':\n",
    "        args.model_path = '../model/{}/{}.pt'.format(init_args.model_name, log_file_name)\n",
    "\n",
    "    utils.check_dir(args.log_file)\n",
    "    logging.basicConfig(filename=args.log_file, level=args.verbose)\n",
    "    logging.getLogger().addHandler(logging.StreamHandler(sys.stdout))\n",
    "    logging.info(init_args)\n",
    "    \n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fc6ea60",
   "metadata": {
    "cellId": "0ba3pzzsxjc25jn0726klcj"
   },
   "outputs": [],
   "source": [
    "def run_model():\n",
    "    logging.info('-' * 45 + ' BEGIN: ' + utils.get_time() + ' ' + '-' * 45)\n",
    "    exclude = ['check_epoch', 'log_file', 'model_path', 'path', 'pin_memory', 'load',\n",
    "               'regenerate', 'sep', 'train', 'verbose', 'metric', 'test_epoch', 'buffer']\n",
    "    logging.info(utils.format_arg_str(args, exclude_lst=exclude))\n",
    "\n",
    "    # Random seed\n",
    "    np.random.seed(args.random_seed)\n",
    "    torch.manual_seed(args.random_seed)\n",
    "    torch.cuda.manual_seed(args.random_seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    # GPU\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
    "    logging.info('GPU available: {}'.format(torch.cuda.is_available()))\n",
    "\n",
    "    # # Read data\n",
    "    corpus_path = os.path.join(args.path, args.dataset, model_name.reader + '.pkl')\n",
    "    if not args.regenerate and os.path.exists(corpus_path):\n",
    "        logging.info('Load corpus from {}'.format(corpus_path))\n",
    "        corpus = pickle.load(open(corpus_path, 'rb'))\n",
    "    else:\n",
    "        corpus = reader_name(args)\n",
    "        logging.info('Save corpus to {}'.format(corpus_path))\n",
    "        pickle.dump(corpus, open(corpus_path, 'wb'))\n",
    "\n",
    "    # # Define model\n",
    "    model = model_name(args, corpus)\n",
    "    logging.info(model)\n",
    "    model.apply(model.init_weights)\n",
    "    model.actions_before_train()\n",
    "    model.to(model.device)\n",
    "\n",
    "    # Run model\n",
    "    data_dict = dict()\n",
    "    for phase in ['train', 'dev', 'test']:\n",
    "        data_dict[phase] = model_name.Dataset(model, corpus, phase)\n",
    "    runner = runner_name(args)\n",
    "    if args.load > 0:\n",
    "        model.load_model()\n",
    "    if args.train > 0:\n",
    "        runner.train(data_dict)\n",
    "    logging.info(os.linesep + 'Test After Training: ' + runner.print_res(data_dict['test']))\n",
    "\n",
    "    model.actions_after_train()\n",
    "    logging.info(os.linesep + '-' * 45 + ' END: ' + utils.get_time() + ' ' + '-' * 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0c0484",
   "metadata": {
    "cellId": "iovp1bnhpueapbzv3zixc"
   },
   "source": [
    "### KDA by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4ee4109d",
   "metadata": {
    "cellId": "hyfyzpohtilikl4410y02"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME  = 'KDA'  \n",
    "EMB_SIZE    = 40   \n",
    "LR          = 1e-3\n",
    "L2          = 1e-6\n",
    "DATASET     = 'ta_feng'  \n",
    "BATCH_SIZE  = 64   \n",
    "EPOCH       = 10   \n",
    "TOP_K       = '5,10,15'   \n",
    "VERBOSE     = 20   \n",
    "NUM_WORKERS = 4   \n",
    "RANDOM_SEED = 3500   \n",
    "TIME_SCALAR = (60 * 60 * 24) * 14\n",
    "CAT_COL     = 'i_category'\n",
    "POOLING     = 'average'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "09ecebce",
   "metadata": {
    "cellId": "cypvhcsgjykmi21v2ofvmp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(dataset='ta_feng', model_name='KDA')\n"
     ]
    }
   ],
   "source": [
    "args = parse_args()\n",
    "args.batch_size      = BATCH_SIZE\n",
    "args.dataset         = DATASET        \n",
    "args.emb_size        = EMB_SIZE\n",
    "args.epoch           = EPOCH\n",
    "args.topk            = TOP_K\n",
    "args.verbose         = VERBOSE\n",
    "args.eval_batch_size = BATCH_SIZE   \n",
    "args.num_workers     = NUM_WORKERS\n",
    "args.random_seed     = RANDOM_SEED\n",
    "args.time_scalar     = TIME_SCALAR\n",
    "args.category_col    = CAT_COL   \n",
    "args.test_all        = 1   \n",
    "args.pooling         = POOLING\n",
    "# args.rnn_model       = RNN\n",
    "\n",
    "model_name = eval('{0}.{0}'.format(MODEL_NAME))\n",
    "reader_name = eval('{0}.{0}'.format(model_name.reader))\n",
    "runner_name = eval('{0}.{0}'.format(model_name.runner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5f832205",
   "metadata": {
    "cellId": "j10xko8j1l4i5pnobylyj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(attention_size=10, batch_size=64, buffer=1, category_col='i_category', check_epoch=1, dataset='ta_feng', dropout=0, early_stop=10, emb_size=40, epoch=10, eval_batch_size=64, freq_rand=0, gamma=-1, gpu='0', history_max=20, include_attr=0, include_val=1, l2=0, load=0, log_file='../log/KDA/KDA__ta_feng__3500__average__lr=0.001__l2=0__num_layers=1__num_heads=1__gamma=-1__freq_rand=0__include_val=1.txt', lr=0.001, metric='NDCG,HR', model_path='../model/KDA/KDA__ta_feng__3500__average__lr=0.001__l2=0__num_layers=1__num_heads=1__gamma=-1__freq_rand=0__include_val=1.pt', n_dft=64, neg_head_p=0.5, num_heads=1, num_layers=1, num_neg=1, num_workers=4, optimizer='Adam', path='../data/', pin_memory=0, pooling='average', random_seed=3500, regenerate=0, sep='\\t', t_scalar=60, test_all=1, test_epoch=-1, time_scalar=1209600, topk='5,10,15', train=1, verbose=20)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "27e73037",
   "metadata": {
    "cellId": "oiz5sdfe5ki1jop77fsb71"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- BEGIN: 2022-05-30 01:26:02 ---------------------------------------------\n",
      "\n",
      "==============================\n",
      " Arguments       | Values     \n",
      "==============================\n",
      " attention_size  | 10        \n",
      " batch_size      | 64        \n",
      " category_col    | i_category\n",
      " dataset         | ta_feng   \n",
      " dropout         | 0         \n",
      " early_stop      | 10        \n",
      " emb_size        | 40        \n",
      " epoch           | 10        \n",
      " eval_batch_size | 64        \n",
      " freq_rand       | 0         \n",
      " gamma           | -1        \n",
      " gpu             | 0         \n",
      " history_max     | 20        \n",
      " include_attr    | 0         \n",
      " include_val     | 1         \n",
      " l2              | 0         \n",
      " lr              | 0.001     \n",
      " n_dft           | 64        \n",
      " neg_head_p      | 0.5       \n",
      " num_heads       | 1         \n",
      " num_layers      | 1         \n",
      " num_neg         | 1         \n",
      " num_workers     | 4         \n",
      " optimizer       | Adam      \n",
      " pooling         | average   \n",
      " random_seed     | 3500      \n",
      " t_scalar        | 60        \n",
      " test_all        | 1         \n",
      " time_scalar     | 1209600   \n",
      " topk            | 5,10,15   \n",
      "==============================\n",
      "GPU available: True\n",
      "Reading data from \"../data/\", dataset = \"ta_feng\" \n",
      "Counting dataset statistics...\n",
      "\"# user\": 19360, \"# item\": 10561, \"# entry\": 686390\n",
      "Appending history info...\n",
      "Constructing relation triplets...\n",
      "Item-item relations:['r_complement', 'r_substitute']\n",
      "\"# relation\": 3, \"# triplet\": 139406\n",
      "Save corpus to ../data/ta_feng/DFTReader.pkl\n",
      "#params: 1215960\n",
      "KDA(\n",
      "  (user_embeddings): Embedding(19361, 40)\n",
      "  (entity_embeddings): Embedding(10562, 40)\n",
      "  (relation_embeddings): Embedding(3, 40)\n",
      "  (relational_dynamic_aggregation): RelationalDynamicAggregation(\n",
      "    (relation_embeddings): Embedding(3, 40)\n",
      "    (freq_real): Embedding(3, 33)\n",
      "    (freq_imag): Embedding(3, 33)\n",
      "  )\n",
      "  (attn_head): MultiHeadAttention(\n",
      "    (q_linear): Linear(in_features=40, out_features=40, bias=False)\n",
      "    (k_linear): Linear(in_features=40, out_features=40, bias=False)\n",
      "    (v_linear): Linear(in_features=40, out_features=40, bias=False)\n",
      "  )\n",
      "  (W1): Linear(in_features=40, out_features=40, bias=True)\n",
      "  (W2): Linear(in_features=40, out_features=40, bias=True)\n",
      "  (dropout_layer): Dropout(p=0, inplace=False)\n",
      "  (layer_norm): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
      "  (item_bias): Embedding(10562, 1)\n",
      ")\n",
      "Optimizer: Adam\n",
      "Epoch 1     loss=0.5514 [141.7 s]    dev=(HR@5:0.0659,NDCG@5:0.0466) [92.8 s] *\n",
      "Epoch 2     loss=0.3766 [140.5 s]    dev=(HR@5:0.0873,NDCG@5:0.0597) [90.3 s] *\n",
      "Epoch 3     loss=0.3065 [141.7 s]    dev=(HR@5:0.0979,NDCG@5:0.0676) [89.9 s] *\n",
      "Epoch 4     loss=0.2703 [140.4 s]    dev=(HR@5:0.1054,NDCG@5:0.0728) [93.2 s] *\n",
      "Epoch 5     loss=0.2433 [141.3 s]    dev=(HR@5:0.1048,NDCG@5:0.0724) [94.2 s]\n",
      "Epoch 6     loss=0.2227 [142.2 s]    dev=(HR@5:0.1061,NDCG@5:0.0733) [92.4 s] *\n",
      "Epoch 7     loss=0.2063 [141.4 s]    dev=(HR@5:0.1075,NDCG@5:0.0741) [90.8 s] *\n",
      "Epoch 8     loss=0.1918 [142.7 s]    dev=(HR@5:0.1045,NDCG@5:0.0730) [90.9 s]\n",
      "Epoch 9     loss=0.1802 [141.0 s]    dev=(HR@5:0.1068,NDCG@5:0.0740) [88.2 s]\n",
      "Epoch 10    loss=0.1698 [140.4 s]    dev=(HR@5:0.1069,NDCG@5:0.0738) [90.4 s]\n",
      "\n",
      "Best Iter(dev)=    7\t dev=(HR@5:0.1075,NDCG@5:0.0741) [2326.9 s] \n",
      "Load model from ../model/KDA/KDA__ta_feng__3500__average__lr=0.001__l2=0__num_layers=1__num_heads=1__gamma=-1__freq_rand=0__include_val=1.pt\n",
      "\n",
      "Test After Training: (HR@5:0.1149,NDCG@5:0.0808,HR@10:0.1559,NDCG@10:0.0940,HR@15:0.1849,NDCG@15:0.1016)\n",
      "\n",
      "--------------------------------------------- END: 2022-05-30 02:09:15 ---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "run_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da55da31",
   "metadata": {
    "cellId": "sk13zz6jl1uqu89leibj8"
   },
   "source": [
    "### KDA+LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f743a3d",
   "metadata": {
    "cellId": "qmyp14b576fxb2xxytyb7j"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME  = 'KDA_RNN' \n",
    "EMB_SIZE    = 40   \n",
    "LR          = 1e-3\n",
    "L2          = 1e-6\n",
    "DATASET     = 'ta_feng'   \n",
    "BATCH_SIZE  = 64   \n",
    "EPOCH       = 10   \n",
    "TOP_K       = '5,10,15'   \n",
    "VERBOSE     = 20   \n",
    "NUM_WORKERS = 4   \n",
    "RANDOM_SEED = 3500   \n",
    "TIME_SCALAR = (60 * 60 * 24) * 14  \n",
    "CAT_COL     = 'i_category'\n",
    "POOLING     = 'average'\n",
    "RNN         = 'lstm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abb9d570",
   "metadata": {
    "cellId": "nod34ahhfzl5p3ha2wf1n3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(dataset='ta_feng', model_name='KDA_RNN', rnn_model='lstm')\n"
     ]
    }
   ],
   "source": [
    "args = parse_args_kda()\n",
    "args.batch_size      = BATCH_SIZE\n",
    "args.dataset         = DATASET        \n",
    "args.emb_size        = EMB_SIZE\n",
    "args.epoch           = EPOCH\n",
    "args.topk            = TOP_K\n",
    "args.verbose         = VERBOSE\n",
    "args.eval_batch_size = BATCH_SIZE   \n",
    "args.num_workers     = NUM_WORKERS\n",
    "args.random_seed     = RANDOM_SEED\n",
    "args.model_name      = MODEL_NAME     \n",
    "args.time_scalar     = TIME_SCALAR\n",
    "args.category_col    = CAT_COL   \n",
    "args.test_all        = 1  \n",
    "args.pooling         = POOLING\n",
    "args.time_max        = 20\n",
    "args.rnn_model       = 'lstm'\n",
    "\n",
    "model_name = eval('{0}.{0}'.format(MODEL_NAME))\n",
    "reader_name = eval('{0}.{0}'.format(model_name.reader))\n",
    "runner_name = eval('{0}.{0}'.format(model_name.runner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9766f1f",
   "metadata": {
    "cellId": "3rpyzj9u8d29np7irt09wg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- BEGIN: 2022-05-30 15:22:58 ---------------------------------------------\n",
      "\n",
      "==============================\n",
      " Arguments       | Values     \n",
      "==============================\n",
      " attention_size  | 10        \n",
      " batch_size      | 64        \n",
      " category_col    | i_category\n",
      " dataset         | ta_feng   \n",
      " dropout         | 0         \n",
      " early_stop      | 10        \n",
      " emb_size        | 40        \n",
      " epoch           | 10        \n",
      " eval_batch_size | 64        \n",
      " freq_rand       | 0         \n",
      " gamma           | -1        \n",
      " gpu             | 0         \n",
      " history_max     | 20        \n",
      " include_attr    | 0         \n",
      " include_val     | 1         \n",
      " l2              | 0         \n",
      " lr              | 0.001     \n",
      " model_name      | KDA_RNN   \n",
      " n_dft           | 64        \n",
      " neg_head_p      | 0.5       \n",
      " num_heads       | 1         \n",
      " num_layers      | 1         \n",
      " num_neg         | 1         \n",
      " num_workers     | 4         \n",
      " optimizer       | Adam      \n",
      " pooling         | average   \n",
      " random_seed     | 3500      \n",
      " rnn_model       | lstm      \n",
      " t_scalar        | 60        \n",
      " test_all        | 1         \n",
      " time_max        | 20        \n",
      " time_scalar     | 1209600   \n",
      " topk            | 5,10,15   \n",
      "==============================\n",
      "GPU available: True\n",
      "Load corpus from ../data/ta_feng/DFTReader.pkl\n",
      "#params: 1308800\n",
      "KDA_RNN(\n",
      "  (user_embeddings): Embedding(19361, 40, padding_idx=0)\n",
      "  (entity_embeddings): Embedding(10562, 40)\n",
      "  (relation_embeddings): Embedding(3, 40)\n",
      "  (relational_dynamic_aggregation): RelationalDynamicAggregation(\n",
      "    (relation_embeddings): Embedding(3, 40)\n",
      "    (freq_real): Embedding(3, 33)\n",
      "    (freq_imag): Embedding(3, 33)\n",
      "  )\n",
      "  (attn_head): MultiHeadAttention(\n",
      "    (q_linear): Linear(in_features=40, out_features=40, bias=False)\n",
      "    (k_linear): Linear(in_features=40, out_features=40, bias=False)\n",
      "    (v_linear): Linear(in_features=40, out_features=40, bias=False)\n",
      "  )\n",
      "  (W1): Linear(in_features=40, out_features=40, bias=True)\n",
      "  (W2): Linear(in_features=40, out_features=40, bias=True)\n",
      "  (dropout_layer): Dropout(p=0, inplace=False)\n",
      "  (layer_norm): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
      "  (item_bias): Embedding(10562, 1)\n",
      "  (emb_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (rnn): LSTM(40, 80, num_layers=2, bias=False, batch_first=True)\n",
      "  (dense): Linear(in_features=80, out_features=40, bias=True)\n",
      ")\n",
      "Optimizer: Adam\n",
      "Epoch 1     loss=0.5575 [172.5 s]    dev=(HR@5:0.0616,NDCG@5:0.0440) [87.1 s] *\n",
      "Epoch 2     loss=0.3885 [169.5 s]    dev=(HR@5:0.0871,NDCG@5:0.0607) [91.0 s] *\n",
      "Epoch 3     loss=0.3263 [170.9 s]    dev=(HR@5:0.0986,NDCG@5:0.0687) [91.5 s] *\n",
      "Epoch 4     loss=0.2999 [169.3 s]    dev=(HR@5:0.1091,NDCG@5:0.0777) [90.9 s] *\n",
      "Epoch 5     loss=0.2820 [170.3 s]    dev=(HR@5:0.1091,NDCG@5:0.0758) [94.0 s]\n",
      "Epoch 6     loss=0.2703 [172.3 s]    dev=(HR@5:0.1157,NDCG@5:0.0810) [96.0 s] *\n",
      "Epoch 7     loss=0.2601 [170.6 s]    dev=(HR@5:0.1191,NDCG@5:0.0841) [90.2 s] *\n",
      "Epoch 8     loss=0.2507 [172.4 s]    dev=(HR@5:0.1213,NDCG@5:0.0866) [91.9 s] *\n",
      "Epoch 9     loss=0.2449 [171.5 s]    dev=(HR@5:0.1236,NDCG@5:0.0864) [91.1 s]\n",
      "Epoch 10    loss=0.2387 [170.7 s]    dev=(HR@5:0.1236,NDCG@5:0.0892) [90.9 s] *\n",
      "\n",
      "Best Iter(dev)=   10\t dev=(HR@5:0.1236,NDCG@5:0.0892) [2625.7 s] \n",
      "Load model from ../model/KDA_RNN/KDA_RNN__ta_feng__lstm__3500__average__lr=0.001__l2=0__num_layers=1__num_heads=1__gamma=-1__freq_rand=0__include_val=1.pt\n",
      "\n",
      "Test After Training: (HR@5:0.1347,NDCG@5:0.0983,HR@10:0.1733,NDCG@10:0.1109,HR@15:0.1981,NDCG@15:0.1174)\n",
      "\n",
      "--------------------------------------------- END: 2022-05-30 16:10:16 ---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "run_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec881ca",
   "metadata": {
    "cellId": "68h333iv1lx4zohukh4jqw"
   },
   "source": [
    "### KDA+GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba5d047a",
   "metadata": {
    "cellId": "lmwekce11ew4adqklmhhi"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME  = 'KDA_RNN' \n",
    "EMB_SIZE    = 40   \n",
    "LR          = 1e-3\n",
    "L2          = 1e-6\n",
    "DATASET     = 'ta_feng'   \n",
    "BATCH_SIZE  = 64   \n",
    "EPOCH       = 10   \n",
    "TOP_K       = '5,10,15'   \n",
    "VERBOSE     = 20   \n",
    "NUM_WORKERS = 4   \n",
    "RANDOM_SEED = 3500   \n",
    "TIME_SCALAR = (60 * 60 * 24) * 14  \n",
    "CAT_COL     = 'i_category'\n",
    "POOLING     = 'average'\n",
    "RNN         = 'gru'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e47aa5b",
   "metadata": {
    "cellId": "59fcyjtq7rf9tr876kn9n7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(dataset='ta_feng', model_name='KDA_RNN', rnn_model='gru')\n"
     ]
    }
   ],
   "source": [
    "args = parse_args_kda()\n",
    "args.batch_size      = BATCH_SIZE\n",
    "args.dataset         = DATASET        \n",
    "args.emb_size        = EMB_SIZE\n",
    "args.epoch           = EPOCH\n",
    "args.topk            = TOP_K\n",
    "args.verbose         = VERBOSE\n",
    "args.eval_batch_size = BATCH_SIZE   \n",
    "args.num_workers     = NUM_WORKERS\n",
    "args.random_seed     = RANDOM_SEED\n",
    "args.model_name      = MODEL_NAME     \n",
    "args.time_scalar     = TIME_SCALAR\n",
    "args.category_col    = CAT_COL   \n",
    "args.test_all        = 1  \n",
    "args.pooling         = POOLING\n",
    "args.time_max        = 20\n",
    "args.rnn_model       = RNN\n",
    "\n",
    "model_name = eval('{0}.{0}'.format(MODEL_NAME))\n",
    "reader_name = eval('{0}.{0}'.format(model_name.reader))\n",
    "runner_name = eval('{0}.{0}'.format(model_name.runner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea675583",
   "metadata": {
    "cellId": "t02ja7xe2rlcyntwgnzmyr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- BEGIN: 2022-05-30 16:47:06 ---------------------------------------------\n",
      "\n",
      "==============================\n",
      " Arguments       | Values     \n",
      "==============================\n",
      " attention_size  | 10        \n",
      " batch_size      | 64        \n",
      " category_col    | i_category\n",
      " dataset         | ta_feng   \n",
      " dropout         | 0         \n",
      " early_stop      | 10        \n",
      " emb_size        | 40        \n",
      " epoch           | 10        \n",
      " eval_batch_size | 64        \n",
      " freq_rand       | 0         \n",
      " gamma           | -1        \n",
      " gpu             | 0         \n",
      " history_max     | 20        \n",
      " include_attr    | 0         \n",
      " include_val     | 1         \n",
      " l2              | 0         \n",
      " lr              | 0.001     \n",
      " model_name      | KDA_RNN   \n",
      " n_dft           | 64        \n",
      " neg_head_p      | 0.5       \n",
      " num_heads       | 1         \n",
      " num_layers      | 1         \n",
      " num_neg         | 1         \n",
      " num_workers     | 4         \n",
      " optimizer       | Adam      \n",
      " pooling         | average   \n",
      " random_seed     | 3500      \n",
      " rnn_model       | gru       \n",
      " t_scalar        | 60        \n",
      " test_all        | 1         \n",
      " time_max        | 20        \n",
      " time_scalar     | 1209600   \n",
      " topk            | 5,10,15   \n",
      "==============================\n",
      "GPU available: True\n",
      "Load corpus from ../data/ta_feng/DFTReader.pkl\n",
      "#params: 1286400\n",
      "KDA_RNN(\n",
      "  (user_embeddings): Embedding(19361, 40, padding_idx=0)\n",
      "  (entity_embeddings): Embedding(10562, 40)\n",
      "  (relation_embeddings): Embedding(3, 40)\n",
      "  (relational_dynamic_aggregation): RelationalDynamicAggregation(\n",
      "    (relation_embeddings): Embedding(3, 40)\n",
      "    (freq_real): Embedding(3, 33)\n",
      "    (freq_imag): Embedding(3, 33)\n",
      "  )\n",
      "  (attn_head): MultiHeadAttention(\n",
      "    (q_linear): Linear(in_features=40, out_features=40, bias=False)\n",
      "    (k_linear): Linear(in_features=40, out_features=40, bias=False)\n",
      "    (v_linear): Linear(in_features=40, out_features=40, bias=False)\n",
      "  )\n",
      "  (W1): Linear(in_features=40, out_features=40, bias=True)\n",
      "  (W2): Linear(in_features=40, out_features=40, bias=True)\n",
      "  (dropout_layer): Dropout(p=0, inplace=False)\n",
      "  (layer_norm): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
      "  (item_bias): Embedding(10562, 1)\n",
      "  (emb_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (rnn): GRU(40, 80, num_layers=2, bias=False, batch_first=True)\n",
      "  (dense): Linear(in_features=80, out_features=40, bias=True)\n",
      ")\n",
      "Optimizer: Adam\n",
      "Epoch 1     loss=0.5672 [170.1 s]    dev=(HR@5:0.0539,NDCG@5:0.0404) [95.5 s] *\n",
      "Epoch 2     loss=0.4054 [172.2 s]    dev=(HR@5:0.0843,NDCG@5:0.0588) [93.1 s] *\n",
      "Epoch 3     loss=0.3360 [171.9 s]    dev=(HR@5:0.0993,NDCG@5:0.0710) [92.4 s] *\n",
      "Epoch 4     loss=0.3061 [170.8 s]    dev=(HR@5:0.1064,NDCG@5:0.0758) [92.0 s] *\n",
      "Epoch 5     loss=0.2880 [171.0 s]    dev=(HR@5:0.1131,NDCG@5:0.0792) [90.2 s] *\n",
      "Epoch 6     loss=0.2738 [173.2 s]    dev=(HR@5:0.1184,NDCG@5:0.0843) [92.8 s] *\n",
      "Epoch 7     loss=0.2636 [170.6 s]    dev=(HR@5:0.1206,NDCG@5:0.0855) [90.9 s] *\n",
      "Epoch 8     loss=0.2543 [172.4 s]    dev=(HR@5:0.1231,NDCG@5:0.0865) [90.6 s] *\n",
      "Epoch 9     loss=0.2480 [172.9 s]    dev=(HR@5:0.1163,NDCG@5:0.0823) [91.5 s]\n",
      "Epoch 10    loss=0.2411 [172.1 s]    dev=(HR@5:0.1242,NDCG@5:0.0870) [93.2 s] *\n",
      "\n",
      "Best Iter(dev)=   10\t dev=(HR@5:0.1242,NDCG@5:0.0870) [2640.7 s] \n",
      "Load model from ../model/KDA_RNN/KDA_RNN__ta_feng__gru__3500__average__lr=0.001__l2=0__num_layers=1__num_heads=1__gamma=-1__freq_rand=0__include_val=1.pt\n",
      "\n",
      "Test After Training: (HR@5:0.1306,NDCG@5:0.0938,HR@10:0.1722,NDCG@10:0.1071,HR@15:0.1979,NDCG@15:0.1140)\n",
      "\n",
      "--------------------------------------------- END: 2022-05-30 17:34:48 ---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "run_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bb6ecb",
   "metadata": {
    "cellId": "5zw5z8dwrx88k3hredsugf"
   },
   "source": [
    "### Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e858318b",
   "metadata": {
    "cellId": "c80q8mgidapw38wj4hryi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(dataset='ttrs', model_name='SLRCPlus')\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME  = 'SLRCPlus' \n",
    "EMB_SIZE    = 40   \n",
    "LR          = 1e-3\n",
    "L2          = 1e-6\n",
    "DATASET     = 'ttrs'\n",
    "BATCH_SIZE  = 64   \n",
    "EPOCH       = 10   \n",
    "TOP_K       = '5,10,15'   \n",
    "VERBOSE     = 20   \n",
    "NUM_WORKERS = 4   \n",
    "RANDOM_SEED = 3500   \n",
    "TIME_SCALAR = (60 * 60 * 24) * 14 # 14 days per interval\n",
    "CAT_COL     = 'i_category'\n",
    "POOLING     = 'average'\n",
    "\n",
    "args = parse_args()\n",
    "\n",
    "args.batch_size      = BATCH_SIZE\n",
    "args.dataset         = DATASET        \n",
    "args.emb_size        = EMB_SIZE\n",
    "args.epoch           = EPOCH\n",
    "args.topk            = TOP_K\n",
    "args.verbose         = VERBOSE\n",
    "args.eval_batch_size = BATCH_SIZE   \n",
    "args.num_workers     = NUM_WORKERS\n",
    "args.random_seed     = RANDOM_SEED\n",
    "args.model_name      = MODEL_NAME     \n",
    "args.time_scalar     = TIME_SCALAR\n",
    "args.category_col    = CAT_COL   \n",
    "args.test_all        = 1  \n",
    "args.pooling         = POOLING\n",
    "args.time_max        = 20\n",
    "\n",
    "model_name = eval('{0}.{0}'.format(MODEL_NAME))\n",
    "reader_name = eval('{0}.{0}'.format(model_name.reader))\n",
    "runner_name = eval('{0}.{0}'.format(model_name.runner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a99edf78",
   "metadata": {
    "cellId": "6ro2ycomr3jrsf82hu5n5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(batch_size=64, buffer=1, category_col='i_category', check_epoch=1, dataset='ttrs', dropout=0, early_stop=10, emb_size=40, epoch=10, eval_batch_size=64, gpu='0', history_max=20, include_attr=0, l2=0, load=0, log_file='../log/SLRCPlus/SLRCPlus__ttrs__3500__average__lr=0.001__l2=0__emb_size=64.txt', lr=0.001, metric='NDCG,HR', model_name='SLRCPlus', model_path='../model/SLRCPlus/SLRCPlus__ttrs__3500__average__lr=0.001__l2=0__emb_size=64.pt', num_neg=1, num_workers=4, optimizer='Adam', path='../data/', pin_memory=0, pooling='average', random_seed=3500, regenerate=0, sep='\\t', test_all=1, test_epoch=-1, time_max=20, time_scalar=1209600, topk='5,10,15', train=1, verbose=20)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7954d95d",
   "metadata": {
    "cellId": "hpfr0xk7el4ao83im251h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True\n",
      "Load corpus from ../data/ttrs/KGReader.pkl\n",
      "#params: 914946\n",
      "SLRCPlus(\n",
      "  (u_embeddings): Embedding(20465, 40)\n",
      "  (i_embeddings): Embedding(1355, 40)\n",
      "  (user_bias): Embedding(20465, 1)\n",
      "  (item_bias): Embedding(1355, 1)\n",
      "  (alphas): Embedding(1355, 3)\n",
      "  (pis): Embedding(1355, 3)\n",
      "  (betas): Embedding(1355, 3)\n",
      "  (sigmas): Embedding(1355, 3)\n",
      "  (mus): Embedding(1355, 3)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SLRCPlus(\n",
       "  (u_embeddings): Embedding(20465, 40)\n",
       "  (i_embeddings): Embedding(1355, 40)\n",
       "  (user_bias): Embedding(20465, 1)\n",
       "  (item_bias): Embedding(1355, 1)\n",
       "  (alphas): Embedding(1355, 3)\n",
       "  (pis): Embedding(1355, 3)\n",
       "  (betas): Embedding(1355, 3)\n",
       "  (sigmas): Embedding(1355, 3)\n",
       "  (mus): Embedding(1355, 3)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random seed\n",
    "np.random.seed(args.random_seed)\n",
    "torch.manual_seed(args.random_seed)\n",
    "torch.cuda.manual_seed(args.random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
    "logging.info('GPU available: {}'.format(torch.cuda.is_available()))\n",
    "\n",
    "# # Read data\n",
    "corpus_path = os.path.join(args.path, args.dataset, model_name.reader + '.pkl')\n",
    "if not args.regenerate and os.path.exists(corpus_path):\n",
    "    logging.info('Load corpus from {}'.format(corpus_path))\n",
    "    corpus = pickle.load(open(corpus_path, 'rb'))\n",
    "else:\n",
    "    corpus = reader_name(args)\n",
    "    logging.info('Save corpus to {}'.format(corpus_path))\n",
    "    pickle.dump(corpus, open(corpus_path, 'wb'))\n",
    "\n",
    "# # Define model\n",
    "model = model_name(args, corpus)\n",
    "logging.info(model)\n",
    "model.apply(model.init_weights)\n",
    "model.actions_before_train()\n",
    "model.to(model.device)\n",
    "\n",
    "# # Run model\n",
    "data_dict = dict()\n",
    "for phase in ['test']:\n",
    "    data_dict[phase] = model_name.Dataset(model, corpus, phase)\n",
    "runner = runner_name(args)\n",
    "logging.info(os.linesep + 'Загрузка модели')\n",
    "model.load_model()\n",
    "\n",
    "runner = runner_name(args)\n",
    "logging.info(os.linesep + 'Получение предсказаний')\n",
    "predictions = runner.predict(data_dict['test'])\n",
    "logging.info(os.linesep + 'Сохранение предсказаний')\n",
    "pd.DataFrame.from_records(predictions).to_csv(f'{MODEL_NAME}_prob.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0580e810",
   "metadata": {
    "cellId": "2sj5h6bmxhw5gbp2qm8sol"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " (20464, 1355)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "runner = runner_name(args)\n",
    "predictions = runner.predict(data_dict['test'])\n",
    "print('\\n', predictions.shape) # U x I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f156a487",
   "metadata": {
    "cellId": "af88qfiffrnjw1brzero"
   },
   "source": [
    "### SLRC+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf1c75df",
   "metadata": {
    "cellId": "f0usy6gsjc65dl5ns8hzfq"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME  = 'SLRCPlus' \n",
    "EMB_SIZE    = 40   \n",
    "LR          = 1e-3\n",
    "L2          = 1e-6\n",
    "DATASET     = 'ta_feng'\n",
    "BATCH_SIZE  = 64   \n",
    "EPOCH       = 10   \n",
    "TOP_K       = '5,10,15'   \n",
    "VERBOSE     = 20   \n",
    "NUM_WORKERS = 4   \n",
    "RANDOM_SEED = 3500   \n",
    "TIME_SCALAR = (60 * 60 * 24) * 14 # 14 days per interval\n",
    "CAT_COL     = 'i_category'\n",
    "POOLING     = 'average'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d84748e",
   "metadata": {
    "cellId": "v3o4jpmyz9djgkv488w1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(dataset='ta_feng', model_name='SLRCPlus')\n"
     ]
    }
   ],
   "source": [
    "args = parse_args()\n",
    "args.batch_size      = BATCH_SIZE\n",
    "args.dataset         = DATASET        \n",
    "args.emb_size        = EMB_SIZE\n",
    "args.epoch           = EPOCH\n",
    "args.topk            = TOP_K\n",
    "args.verbose         = VERBOSE\n",
    "args.eval_batch_size = BATCH_SIZE \n",
    "args.num_workers     = NUM_WORKERS\n",
    "args.random_seed     = RANDOM_SEED\n",
    "args.time_scalar     = TIME_SCALAR\n",
    "args.category_col    = CAT_COL   \n",
    "args.test_all        = 1  \n",
    "args.pooling         = POOLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30ac9433",
   "metadata": {
    "cellId": "gjyxz2zvsblz1os91lm2l"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(batch_size=64, buffer=1, category_col='i_category', check_epoch=1, dataset='ta_feng', dropout=0, early_stop=10, emb_size=40, epoch=10, eval_batch_size=64, gpu='0', history_max=20, include_attr=0, l2=0, load=0, log_file='../log/SLRCPlus/SLRCPlus__ta_feng__3500__average__lr=0.001__l2=0__emb_size=64.txt', lr=0.001, metric='NDCG,HR', model_path='../model/SLRCPlus/SLRCPlus__ta_feng__3500__average__lr=0.001__l2=0__emb_size=64.pt', num_neg=1, num_workers=4, optimizer='Adam', path='../data/', pin_memory=0, pooling='average', random_seed=3500, regenerate=0, sep='\\t', test_all=1, test_epoch=-1, time_scalar=1209600, topk='5,10,15', train=1, verbose=20)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0eed0c5",
   "metadata": {
    "cellId": "3te4cjsx6llvuqc7l14ny"
   },
   "outputs": [],
   "source": [
    "model_name = eval('{0}.{0}'.format(MODEL_NAME))\n",
    "reader_name = eval('{0}.{0}'.format(model_name.reader))\n",
    "runner_name = eval('{0}.{0}'.format(model_name.runner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1a6e5cd",
   "metadata": {
    "cellId": "cdsxyxzf95sbhqr5wfs1eg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- BEGIN: 2022-05-30 09:36:53 ---------------------------------------------\n",
      "\n",
      "==============================\n",
      " Arguments       | Values     \n",
      "==============================\n",
      " batch_size      | 64        \n",
      " category_col    | i_category\n",
      " dataset         | ta_feng   \n",
      " dropout         | 0         \n",
      " early_stop      | 10        \n",
      " emb_size        | 40        \n",
      " epoch           | 10        \n",
      " eval_batch_size | 64        \n",
      " gpu             | 0         \n",
      " history_max     | 20        \n",
      " include_attr    | 0         \n",
      " l2              | 0         \n",
      " lr              | 0.001     \n",
      " num_neg         | 1         \n",
      " num_workers     | 4         \n",
      " optimizer       | Adam      \n",
      " pooling         | average   \n",
      " random_seed     | 3500      \n",
      " test_all        | 1         \n",
      " time_scalar     | 1209600   \n",
      " topk            | 5,10,15   \n",
      "==============================\n",
      "GPU available: True\n",
      "Reading data from \"../data/\", dataset = \"ta_feng\" \n",
      "Counting dataset statistics...\n",
      "\"# user\": 19360, \"# item\": 10561, \"# entry\": 686390\n",
      "Appending history info...\n",
      "Constructing relation triplets...\n",
      "Item-item relations:['r_complement', 'r_substitute']\n",
      "\"# relation\": 3, \"# triplet\": 139406\n",
      "Save corpus to ../data/ta_feng/KGReader.pkl\n",
      "#params: 1385274\n",
      "SLRCPlus(\n",
      "  (u_embeddings): Embedding(19361, 40)\n",
      "  (i_embeddings): Embedding(10562, 40)\n",
      "  (user_bias): Embedding(19361, 1)\n",
      "  (item_bias): Embedding(10562, 1)\n",
      "  (alphas): Embedding(10562, 3)\n",
      "  (pis): Embedding(10562, 3)\n",
      "  (betas): Embedding(10562, 3)\n",
      "  (sigmas): Embedding(10562, 3)\n",
      "  (mus): Embedding(10562, 3)\n",
      ")\n",
      "Optimizer: Adam\n",
      "Epoch 1     loss=0.4731 [72.0 s]    dev=(HR@5:0.0748,NDCG@5:0.0513) [24.8 s] *\n",
      "Epoch 2     loss=0.3785 [73.3 s]    dev=(HR@5:0.0884,NDCG@5:0.0598) [23.5 s] *\n",
      "Epoch 3     loss=0.3526 [74.2 s]    dev=(HR@5:0.0968,NDCG@5:0.0671) [23.6 s] *\n",
      "Epoch 4     loss=0.3183 [74.5 s]    dev=(HR@5:0.0962,NDCG@5:0.0670) [23.5 s]\n",
      "Epoch 5     loss=0.2793 [75.8 s]    dev=(HR@5:0.0975,NDCG@5:0.0699) [23.7 s] *\n",
      "Epoch 6     loss=0.2451 [74.1 s]    dev=(HR@5:0.1013,NDCG@5:0.0703) [23.5 s] *\n",
      "Epoch 7     loss=0.2160 [74.4 s]    dev=(HR@5:0.0994,NDCG@5:0.0680) [23.7 s]\n",
      "Epoch 8     loss=0.1923 [73.9 s]    dev=(HR@5:0.1007,NDCG@5:0.0704) [23.6 s] *\n",
      "Epoch 9     loss=0.1745 [75.7 s]    dev=(HR@5:0.1024,NDCG@5:0.0716) [23.8 s] *\n",
      "Epoch 10    loss=0.1606 [76.8 s]    dev=(HR@5:0.1025,NDCG@5:0.0717) [23.6 s] *\n",
      "\n",
      "Best Iter(dev)=   10\t dev=(HR@5:0.1025,NDCG@5:0.0717) [982.6 s] \n",
      "Load model from ../model/SLRCPlus/SLRCPlus__ta_feng__3500__average__lr=0.001__l2=0__emb_size=64.pt\n",
      "\n",
      "Test After Training: (HR@5:0.1110,NDCG@5:0.0785,HR@10:0.1497,NDCG@10:0.0911,HR@15:0.1710,NDCG@15:0.0967)\n",
      "\n",
      "--------------------------------------------- END: 2022-05-30 12:20:00 ---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "run_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdf1c35",
   "metadata": {
    "cellId": "hlpljr1a4xs48kl08zy1f7"
   },
   "source": [
    "#### TiSASRec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03b0fc76",
   "metadata": {
    "cellId": "d6eeop7gicugnlzl435t2"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME  = 'TiSASRec' \n",
    "EMB_SIZE    = 40   \n",
    "LR          = 1e-3\n",
    "L2          = 1e-6\n",
    "DATASET     = 'ta_feng'   \n",
    "BATCH_SIZE  = 64   \n",
    "EPOCH       = 10   \n",
    "TOP_K       = '5,10,15'   \n",
    "VERBOSE     = 20   \n",
    "NUM_WORKERS = 4   \n",
    "RANDOM_SEED = 3500   \n",
    "TIME_SCALAR = (60 * 60 * 24) * 14  \n",
    "CAT_COL     = 'i_category'\n",
    "POOLING     = 'average'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb9be720",
   "metadata": {
    "cellId": "624w982m5irl644kau27nk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(dataset='ta_feng', model_name='TiSASRec')\n"
     ]
    }
   ],
   "source": [
    "args = parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6533d791",
   "metadata": {
    "cellId": "hb466ixzu973ymiv9zny8f"
   },
   "outputs": [],
   "source": [
    "args.batch_size      = BATCH_SIZE\n",
    "args.dataset         = DATASET        \n",
    "args.emb_size        = EMB_SIZE\n",
    "args.epoch           = EPOCH\n",
    "args.topk            = TOP_K\n",
    "args.verbose         = VERBOSE\n",
    "args.eval_batch_size = BATCH_SIZE   \n",
    "args.num_workers     = NUM_WORKERS\n",
    "args.random_seed     = RANDOM_SEED\n",
    "args.model_name      = MODEL_NAME     \n",
    "args.time_scalar     = TIME_SCALAR\n",
    "args.category_col    = CAT_COL   \n",
    "args.test_all        = 1  \n",
    "args.pooling         = POOLING\n",
    "args.time_max        = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "950e2f2f",
   "metadata": {
    "cellId": "qozra5pkesh0e1p9e0da8wv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(batch_size=64, buffer=1, category_col='i_category', check_epoch=1, dataset='ta_feng', dropout=0, early_stop=10, emb_size=40, epoch=10, eval_batch_size=64, gpu='0', history_max=20, l2=0, load=0, log_file='../log/TiSASRec/TiSASRec__ta_feng__3500__average__lr=0.001__l2=0__emb_size=64__num_layers=1__num_heads=4__time_max=512.txt', lr=0.001, metric='NDCG,HR', model_name='TiSASRec', model_path='../model/TiSASRec/TiSASRec__ta_feng__3500__average__lr=0.001__l2=0__emb_size=64__num_layers=1__num_heads=4__time_max=512.pt', num_heads=4, num_layers=1, num_neg=1, num_workers=4, optimizer='Adam', path='../data/', pin_memory=0, pooling='average', random_seed=3500, regenerate=0, sep='\\t', test_all=1, test_epoch=-1, time_max=20, time_scalar=1209600, topk='5,10,15', train=1, verbose=20)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92b28f35",
   "metadata": {
    "cellId": "igjt1eji7keg7xsv3v3ur"
   },
   "outputs": [],
   "source": [
    "model_name = eval('{0}.{0}'.format(MODEL_NAME))\n",
    "reader_name = eval('{0}.{0}'.format(model_name.reader))\n",
    "runner_name = eval('{0}.{0}'.format(model_name.runner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89137a90",
   "metadata": {
    "cellId": "3wkg2jrwcin02feg33txy1t"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- BEGIN: 2022-05-30 08:28:27 ---------------------------------------------\n",
      "\n",
      "==============================\n",
      " Arguments       | Values     \n",
      "==============================\n",
      " batch_size      | 64        \n",
      " category_col    | i_category\n",
      " dataset         | ta_feng   \n",
      " dropout         | 0         \n",
      " early_stop      | 10        \n",
      " emb_size        | 40        \n",
      " epoch           | 10        \n",
      " eval_batch_size | 64        \n",
      " gpu             | 0         \n",
      " history_max     | 20        \n",
      " l2              | 0         \n",
      " lr              | 0.001     \n",
      " model_name      | TiSASRec  \n",
      " num_heads       | 4         \n",
      " num_layers      | 1         \n",
      " num_neg         | 1         \n",
      " num_workers     | 4         \n",
      " optimizer       | Adam      \n",
      " pooling         | average   \n",
      " random_seed     | 3500      \n",
      " test_all        | 1         \n",
      " time_max        | 20        \n",
      " time_scalar     | 1209600   \n",
      " topk            | 5,10,15   \n",
      "==============================\n",
      "GPU available: True\n",
      "Reading data from \"../data/\", dataset = \"ta_feng\" \n",
      "Counting dataset statistics...\n",
      "\"# user\": 19360, \"# item\": 10561, \"# entry\": 686390\n",
      "Appending history info...\n",
      "Save corpus to ../data/ta_feng/BaseReader.pkl\n",
      "#params: 434200\n",
      "TiSASRec(\n",
      "  (i_embeddings): Embedding(10562, 40)\n",
      "  (p_k_embeddings): Embedding(21, 40)\n",
      "  (p_v_embeddings): Embedding(21, 40)\n",
      "  (t_k_embeddings): Embedding(21, 40)\n",
      "  (t_v_embeddings): Embedding(21, 40)\n",
      "  (transformer_block): ModuleList(\n",
      "    (0): TimeIntervalTransformerLayer(\n",
      "      (masked_attn_head): TimeIntervalMultiHeadAttention(\n",
      "        (v_linear): Linear(in_features=40, out_features=40, bias=True)\n",
      "        (k_linear): Linear(in_features=40, out_features=40, bias=True)\n",
      "        (q_linear): Linear(in_features=40, out_features=40, bias=True)\n",
      "      )\n",
      "      (layer_norm1): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout1): Dropout(p=0, inplace=False)\n",
      "      (linear1): Linear(in_features=40, out_features=40, bias=True)\n",
      "      (linear2): Linear(in_features=40, out_features=40, bias=True)\n",
      "      (layer_norm2): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout2): Dropout(p=0, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Optimizer: Adam\n",
      "Epoch 1     loss=0.4428 [92.3 s]    dev=(HR@5:0.0456,NDCG@5:0.0330) [22.9 s] *\n",
      "Epoch 2     loss=0.3917 [93.9 s]    dev=(HR@5:0.0475,NDCG@5:0.0339) [21.6 s] *\n",
      "Epoch 3     loss=0.3636 [94.9 s]    dev=(HR@5:0.0493,NDCG@5:0.0360) [21.4 s] *\n",
      "Epoch 4     loss=0.3395 [93.0 s]    dev=(HR@5:0.0498,NDCG@5:0.0351) [21.6 s]\n",
      "Epoch 5     loss=0.3172 [92.4 s]    dev=(HR@5:0.0517,NDCG@5:0.0372) [21.5 s] *\n",
      "Epoch 6     loss=0.3002 [92.2 s]    dev=(HR@5:0.0526,NDCG@5:0.0371) [21.5 s]\n",
      "Epoch 7     loss=0.2846 [92.1 s]    dev=(HR@5:0.0512,NDCG@5:0.0346) [21.6 s]\n",
      "Epoch 8     loss=0.2735 [92.2 s]    dev=(HR@5:0.0503,NDCG@5:0.0343) [21.6 s]\n",
      "Epoch 9     loss=0.2640 [92.4 s]    dev=(HR@5:0.0548,NDCG@5:0.0371) [21.7 s]\n",
      "Epoch 10    loss=0.2568 [92.7 s]    dev=(HR@5:0.0538,NDCG@5:0.0365) [21.6 s]\n",
      "\n",
      "Best Iter(dev)=    5\t dev=(HR@5:0.0517,NDCG@5:0.0372) [1145.5 s] \n",
      "Load model from ../model/TiSASRec/TiSASRec__ta_feng__3500__average__lr=0.001__l2=0__emb_size=64__num_layers=1__num_heads=4__time_max=512.pt\n",
      "\n",
      "Test After Training: (HR@5:0.0584,NDCG@5:0.0430,HR@10:0.0846,NDCG@10:0.0514,HR@15:0.1030,NDCG@15:0.0562)\n",
      "\n",
      "--------------------------------------------- END: 2022-05-30 08:48:26 ---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "run_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bba71cc",
   "metadata": {
    "cellId": "c1ss5y3ypwsq1njrakhtf"
   },
   "source": [
    "#### SASRec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "148574dd",
   "metadata": {
    "cellId": "pk7jkdq9gbebhdksv7mf"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME  = 'SASRec' \n",
    "EMB_SIZE    = 40   \n",
    "LR          = 1e-3\n",
    "L2          = 1e-6\n",
    "DATASET     = 'ta_feng'   \n",
    "BATCH_SIZE  = 64   \n",
    "EPOCH       = 10   \n",
    "TOP_K       = '5,10,15'   \n",
    "VERBOSE     = 20   \n",
    "NUM_WORKERS = 4   \n",
    "RANDOM_SEED = 3500   \n",
    "TIME_SCALAR = (60 * 60 * 24) * 14  \n",
    "CAT_COL     = 'i_category'\n",
    "POOLING     = 'average'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ae445ba",
   "metadata": {
    "cellId": "cdu363hvdkd9dpbd84afs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(dataset='ta_feng', model_name='SASRec')\n"
     ]
    }
   ],
   "source": [
    "args = parse_args()\n",
    "args.batch_size      = BATCH_SIZE\n",
    "args.dataset         = DATASET        \n",
    "args.emb_size        = EMB_SIZE\n",
    "args.epoch           = EPOCH\n",
    "args.topk            = TOP_K\n",
    "args.verbose         = VERBOSE\n",
    "args.eval_batch_size = BATCH_SIZE   \n",
    "args.num_workers     = NUM_WORKERS\n",
    "args.random_seed     = RANDOM_SEED\n",
    "args.model_name      = MODEL_NAME     \n",
    "args.time_scalar     = TIME_SCALAR\n",
    "args.category_col    = CAT_COL   \n",
    "args.test_all        = 1  \n",
    "args.pooling         = POOLING\n",
    "args.time_max        = 20\n",
    "\n",
    "model_name = eval('{0}.{0}'.format(MODEL_NAME))\n",
    "reader_name = eval('{0}.{0}'.format(model_name.reader))\n",
    "runner_name = eval('{0}.{0}'.format(model_name.runner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f12bba0",
   "metadata": {
    "cellId": "9x8zq3ymcj4h9idotuct4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- BEGIN: 2022-05-30 09:08:44 ---------------------------------------------\n",
      "\n",
      "==============================\n",
      " Arguments       | Values     \n",
      "==============================\n",
      " batch_size      | 64        \n",
      " category_col    | i_category\n",
      " dataset         | ta_feng   \n",
      " dropout         | 0         \n",
      " early_stop      | 10        \n",
      " emb_size        | 40        \n",
      " epoch           | 10        \n",
      " eval_batch_size | 64        \n",
      " gpu             | 0         \n",
      " history_max     | 20        \n",
      " l2              | 0         \n",
      " lr              | 0.001     \n",
      " model_name      | SASRec    \n",
      " num_heads       | 4         \n",
      " num_layers      | 1         \n",
      " num_neg         | 1         \n",
      " num_workers     | 4         \n",
      " optimizer       | Adam      \n",
      " pooling         | average   \n",
      " random_seed     | 3500      \n",
      " test_all        | 1         \n",
      " time_max        | 20        \n",
      " time_scalar     | 1209600   \n",
      " topk            | 5,10,15   \n",
      "==============================\n",
      "GPU available: True\n",
      "Load corpus from ../data/ta_feng/BaseReader.pkl\n",
      "#params: 431680\n",
      "SASRec(\n",
      "  (i_embeddings): Embedding(10562, 40)\n",
      "  (p_embeddings): Embedding(21, 40)\n",
      "  (transformer_block): ModuleList(\n",
      "    (0): TransformerLayer(\n",
      "      (masked_attn_head): MultiHeadAttention(\n",
      "        (q_linear): Linear(in_features=40, out_features=40, bias=True)\n",
      "        (k_linear): Linear(in_features=40, out_features=40, bias=True)\n",
      "        (v_linear): Linear(in_features=40, out_features=40, bias=True)\n",
      "      )\n",
      "      (layer_norm1): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout1): Dropout(p=0, inplace=False)\n",
      "      (linear1): Linear(in_features=40, out_features=40, bias=True)\n",
      "      (linear2): Linear(in_features=40, out_features=40, bias=True)\n",
      "      (layer_norm2): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout2): Dropout(p=0, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Optimizer: Adam\n",
      "Epoch 1     loss=0.4473 [75.4 s]    dev=(HR@5:0.0403,NDCG@5:0.0300) [21.2 s] *\n",
      "Epoch 2     loss=0.4006 [76.2 s]    dev=(HR@5:0.0431,NDCG@5:0.0306) [21.3 s] *\n",
      "Epoch 3     loss=0.3682 [75.6 s]    dev=(HR@5:0.0486,NDCG@5:0.0348) [21.4 s] *\n",
      "Epoch 4     loss=0.3417 [76.0 s]    dev=(HR@5:0.0536,NDCG@5:0.0381) [21.4 s] *\n",
      "Epoch 5     loss=0.3187 [76.1 s]    dev=(HR@5:0.0495,NDCG@5:0.0349) [21.3 s]\n",
      "Epoch 6     loss=0.3013 [76.8 s]    dev=(HR@5:0.0491,NDCG@5:0.0342) [21.3 s]\n",
      "Epoch 7     loss=0.2865 [76.0 s]    dev=(HR@5:0.0492,NDCG@5:0.0338) [21.4 s]\n",
      "Epoch 8     loss=0.2756 [76.6 s]    dev=(HR@5:0.0502,NDCG@5:0.0343) [21.3 s]\n",
      "Epoch 9     loss=0.2663 [76.1 s]    dev=(HR@5:0.0517,NDCG@5:0.0358) [21.3 s]\n",
      "Epoch 10    loss=0.2588 [75.9 s]    dev=(HR@5:0.0519,NDCG@5:0.0361) [21.5 s]\n",
      "\n",
      "Best Iter(dev)=    4\t dev=(HR@5:0.0536,NDCG@5:0.0381) [974.4 s] \n",
      "Load model from ../model/SASRec/SASRec__ta_feng__3500__average__lr=0.001__l2=0__emb_size=64__num_layers=1__num_heads=4.pt\n",
      "\n",
      "Test After Training: (HR@5:0.0632,NDCG@5:0.0456,HR@10:0.0849,NDCG@10:0.0526,HR@15:0.1012,NDCG@15:0.0569)\n",
      "\n",
      "--------------------------------------------- END: 2022-05-30 09:25:28 ---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "run_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dde47ad",
   "metadata": {
    "cellId": "hyxsf6obhsoz8s6t76bbga"
   },
   "source": [
    "#### Caser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cbead8d",
   "metadata": {
    "cellId": "5ss4ikzgl3gxry9f8w6he"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME  = 'Caser' \n",
    "EMB_SIZE    = 40   \n",
    "LR          = 1e-3\n",
    "L2          = 1e-6\n",
    "DATASET     = 'ta_feng'\n",
    "BATCH_SIZE  = 64   \n",
    "EPOCH       = 10   \n",
    "TOP_K       = '5,10,15'   \n",
    "VERBOSE     = 20   \n",
    "NUM_WORKERS = 4   \n",
    "RANDOM_SEED = 3500   \n",
    "TIME_SCALAR = (60 * 60 * 24) * 14  \n",
    "CAT_COL     = 'i_category'\n",
    "POOLING     = 'average'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bebd46d5",
   "metadata": {
    "cellId": "sfi000j0qdmndf6cg31nzb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(dataset='ta_feng', model_name='Caser')\n"
     ]
    }
   ],
   "source": [
    "args = parse_args()\n",
    "args.batch_size      = BATCH_SIZE\n",
    "args.dataset         = DATASET        \n",
    "args.emb_size        = EMB_SIZE\n",
    "args.epoch           = EPOCH\n",
    "args.topk            = TOP_K\n",
    "args.verbose         = VERBOSE\n",
    "args.eval_batch_size = BATCH_SIZE   \n",
    "args.num_workers     = NUM_WORKERS\n",
    "args.random_seed     = RANDOM_SEED\n",
    "args.model_name      = MODEL_NAME     \n",
    "args.time_scalar     = TIME_SCALAR\n",
    "args.category_col    = CAT_COL   \n",
    "args.test_all        = 1  \n",
    "args.pooling         = POOLING\n",
    "args.time_max        = 20\n",
    "\n",
    "model_name = eval('{0}.{0}'.format(MODEL_NAME))\n",
    "reader_name = eval('{0}.{0}'.format(model_name.reader))\n",
    "runner_name = eval('{0}.{0}'.format(model_name.runner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6821cfe1",
   "metadata": {
    "cellId": "56wbun3ke7f91lc2vpriog"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- BEGIN: 2022-05-30 08:49:20 ---------------------------------------------\n",
      "\n",
      "==============================\n",
      " Arguments       | Values     \n",
      "==============================\n",
      " L               | 4         \n",
      " batch_size      | 64        \n",
      " category_col    | i_category\n",
      " dataset         | ta_feng   \n",
      " dropout         | 0         \n",
      " early_stop      | 10        \n",
      " emb_size        | 40        \n",
      " epoch           | 10        \n",
      " eval_batch_size | 64        \n",
      " gpu             | 0         \n",
      " history_max     | 20        \n",
      " l2              | 0         \n",
      " lr              | 0.001     \n",
      " model_name      | Caser     \n",
      " num_horizon     | 16        \n",
      " num_neg         | 1         \n",
      " num_vertical    | 8         \n",
      " num_workers     | 4         \n",
      " optimizer       | Adam      \n",
      " pooling         | average   \n",
      " random_seed     | 3500      \n",
      " test_all        | 1         \n",
      " time_max        | 20        \n",
      " time_scalar     | 1209600   \n",
      " topk            | 5,10,15   \n",
      "==============================\n",
      "GPU available: True\n",
      "Load corpus from ../data/ta_feng/BaseReader.pkl\n",
      "#params: 1222192\n",
      "Caser(\n",
      "  (u_embeddings): Embedding(19361, 40)\n",
      "  (i_embeddings): Embedding(10562, 40, padding_idx=0)\n",
      "  (conv_h): ModuleList(\n",
      "    (0): Conv2d(1, 16, kernel_size=(1, 40), stride=(1, 1))\n",
      "    (1): Conv2d(1, 16, kernel_size=(2, 40), stride=(1, 1))\n",
      "    (2): Conv2d(1, 16, kernel_size=(3, 40), stride=(1, 1))\n",
      "    (3): Conv2d(1, 16, kernel_size=(4, 40), stride=(1, 1))\n",
      "  )\n",
      "  (conv_v): Conv2d(1, 8, kernel_size=(20, 1), stride=(1, 1))\n",
      "  (fc): Linear(in_features=384, out_features=40, bias=True)\n",
      "  (out): Linear(in_features=80, out_features=40, bias=True)\n",
      ")\n",
      "Optimizer: Adam\n",
      "Epoch 1     loss=0.4537 [79.3 s]    dev=(HR@5:0.0410,NDCG@5:0.0304) [21.3 s] *\n",
      "Epoch 2     loss=0.4158 [76.8 s]    dev=(HR@5:0.0398,NDCG@5:0.0324) [21.3 s] *\n",
      "Epoch 3     loss=0.3878 [77.6 s]    dev=(HR@5:0.0430,NDCG@5:0.0340) [21.2 s] *\n",
      "Epoch 4     loss=0.3619 [77.0 s]    dev=(HR@5:0.0400,NDCG@5:0.0306) [21.4 s]\n",
      "Epoch 5     loss=0.3364 [77.2 s]    dev=(HR@5:0.0405,NDCG@5:0.0317) [21.2 s]\n",
      "Epoch 6     loss=0.3137 [77.5 s]    dev=(HR@5:0.0377,NDCG@5:0.0275) [21.3 s]\n",
      "Epoch 7     loss=0.2937 [77.4 s]    dev=(HR@5:0.0357,NDCG@5:0.0247) [21.4 s]\n",
      "Epoch 8     loss=0.2747 [78.2 s]    dev=(HR@5:0.0372,NDCG@5:0.0277) [21.3 s]\n",
      "Epoch 9     loss=0.2562 [77.4 s]    dev=(HR@5:0.0391,NDCG@5:0.0284) [21.4 s]\n",
      "Epoch 10    loss=0.2410 [78.3 s]    dev=(HR@5:0.0365,NDCG@5:0.0265) [21.6 s]\n",
      "\n",
      "Best Iter(dev)=    3\t dev=(HR@5:0.0430,NDCG@5:0.0340) [990.3 s] \n",
      "Load model from ../model/Caser/Caser__ta_feng__3500__average__lr=0.001__l2=0__emb_size=64__num_horizon=16__num_vertical=8__L=4.pt\n",
      "\n",
      "Test After Training: (HR@5:0.0525,NDCG@5:0.0423,HR@10:0.0686,NDCG@10:0.0475,HR@15:0.0806,NDCG@15:0.0507)\n",
      "\n",
      "--------------------------------------------- END: 2022-05-30 09:06:20 ---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "run_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b433d9a",
   "metadata": {
    "cellId": "ce6kvu538ilhw06l2rr3h"
   },
   "source": [
    "### Chorus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d1ac92",
   "metadata": {
    "cellId": "stq1vnw5pdeorjak7yatw"
   },
   "source": [
    "_STAGE 1: Learn KG embeddings_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae46667d",
   "metadata": {
    "cellId": "b041dvqphhg42fm5cs8i7k"
   },
   "source": [
    "См. в ноутбуке **exp_ttrs.ipynb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429d0240",
   "metadata": {
    "cellId": "2tnjvf87plrpk2u17oao"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME  = 'Chorus' \n",
    "EMB_SIZE    = 40   \n",
    "LR          = 1e-3\n",
    "L2          = 1e-6\n",
    "DATASET     = 'ttrs'   \n",
    "BATCH_SIZE  = 64   \n",
    "EPOCH       = 10   \n",
    "TOP_K       = '5,10,15'   \n",
    "VERBOSE     = 20   \n",
    "NUM_WORKERS = 4   \n",
    "RANDOM_SEED = 3500   \n",
    "TIME_SCALAR = (60 * 60 * 24) * 14  \n",
    "CAT_COL     = 'i_category'\n",
    "POOLING     = 'average'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcc42ae",
   "metadata": {
    "cellId": "u531jmg2nrrrl1f9r438f"
   },
   "outputs": [],
   "source": [
    "args = parse_args()\n",
    "args.batch_size      = BATCH_SIZE\n",
    "args.dataset         = DATASET        \n",
    "args.emb_size        = EMB_SIZE\n",
    "args.epoch           = EPOCH\n",
    "args.topk            = TOP_K\n",
    "args.verbose         = VERBOSE\n",
    "args.eval_batch_size = BATCH_SIZE   \n",
    "args.num_workers     = NUM_WORKERS\n",
    "args.random_seed     = RANDOM_SEED\n",
    "args.model_name      = MODEL_NAME     \n",
    "args.time_scalar     = TIME_SCALAR\n",
    "args.category_col    = CAT_COL   \n",
    "args.test_all        = 1  \n",
    "args.pooling         = POOLING\n",
    "args.time_max        = 20\n",
    "args.stage           = 1\n",
    "\n",
    "model_name = eval('{0}.{0}'.format(MODEL_NAME))\n",
    "reader_name = eval('{0}.{0}'.format(model_name.reader))\n",
    "runner_name = eval('{0}.{0}'.format(model_name.runner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154d3f26",
   "metadata": {
    "cellId": "r6b8agce2kd4mpin409adk"
   },
   "outputs": [],
   "source": [
    "run_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0bc7aa",
   "metadata": {
    "cellId": "wqw00t3u9644ij96lyouj"
   },
   "source": [
    "_STAGE 2: Predict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fb80b54",
   "metadata": {
    "cellId": "qqppa9w6mab227n61xy3b"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME  = 'Chorus' \n",
    "EMB_SIZE    = 40   \n",
    "LR          = 1e-3\n",
    "L2          = 1e-6\n",
    "DATASET     = 'ta_feng'   \n",
    "BATCH_SIZE  = 64   \n",
    "EPOCH       = 10   \n",
    "TOP_K       = '5,10,15'   \n",
    "VERBOSE     = 20   \n",
    "NUM_WORKERS = 4   \n",
    "RANDOM_SEED = 3500   \n",
    "TIME_SCALAR = (60 * 60 * 24) * 14  \n",
    "CAT_COL     = 'i_category'\n",
    "POOLING     = 'average'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ef93608",
   "metadata": {
    "cellId": "fzh0h9omw79ucrlaqc9juk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(dataset='ta_feng', model_name='Chorus')\n"
     ]
    }
   ],
   "source": [
    "args = parse_args()\n",
    "args.batch_size      = BATCH_SIZE\n",
    "args.dataset         = DATASET        \n",
    "args.emb_size        = EMB_SIZE\n",
    "args.epoch           = EPOCH\n",
    "args.topk            = TOP_K\n",
    "args.verbose         = VERBOSE\n",
    "args.eval_batch_size = BATCH_SIZE   \n",
    "args.num_workers     = NUM_WORKERS\n",
    "args.random_seed     = RANDOM_SEED\n",
    "args.model_name      = MODEL_NAME     \n",
    "args.time_scalar     = TIME_SCALAR\n",
    "args.category_col    = CAT_COL   \n",
    "args.test_all        = 1  \n",
    "args.pooling         = POOLING\n",
    "args.time_max        = 20\n",
    "args.stage           = 2\n",
    "\n",
    "model_name = eval('{0}.{0}'.format(MODEL_NAME))\n",
    "reader_name = eval('{0}.{0}'.format(model_name.reader))\n",
    "runner_name = eval('{0}.{0}'.format(model_name.runner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fb81ee6",
   "metadata": {
    "cellId": "7ox9eqhhqkc6ppdv9rxx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- BEGIN: 2022-06-04 12:42:54 ---------------------------------------------\n",
      "\n",
      "==============================\n",
      " Arguments       | Values     \n",
      "==============================\n",
      " base_method     | BPR       \n",
      " batch_size      | 64        \n",
      " category_col    | i_category\n",
      " dataset         | ta_feng   \n",
      " dropout         | 0         \n",
      " early_stop      | 10        \n",
      " emb_size        | 40        \n",
      " epoch           | 10        \n",
      " eval_batch_size | 64        \n",
      " gpu             | 0         \n",
      " history_max     | 20        \n",
      " include_attr    | 0         \n",
      " l2              | 0         \n",
      " lr              | 0.001     \n",
      " lr_scale        | 0.1       \n",
      " margin          | 1         \n",
      " model_name      | Chorus    \n",
      " num_neg         | 1         \n",
      " num_workers     | 4         \n",
      " optimizer       | Adam      \n",
      " pooling         | average   \n",
      " random_seed     | 3500      \n",
      " stage           | 2         \n",
      " test_all        | 1         \n",
      " time_max        | 20        \n",
      " time_scalar     | 1209600   \n",
      " topk            | 5,10,15   \n",
      "==============================\n",
      "GPU available: True\n",
      "Load corpus from ../data/ta_feng/KGReader.pkl\n",
      "#params: 1238964\n",
      "Chorus(\n",
      "  (u_embeddings): Embedding(19361, 40)\n",
      "  (i_embeddings): Embedding(10562, 40)\n",
      "  (r_embeddings): Embedding(3, 40)\n",
      "  (betas): Embedding(1329, 3)\n",
      "  (mus): Embedding(1329, 3)\n",
      "  (sigmas): Embedding(1329, 3)\n",
      "  (prediction): Linear(in_features=40, out_features=1, bias=False)\n",
      "  (user_bias): Embedding(19361, 1)\n",
      "  (item_bias): Embedding(10562, 1)\n",
      "  (kg_loss): MarginRankingLoss()\n",
      ")\n",
      "Load model from ../model/Chorus/KG__ta_feng__emb_size=40__margin=1.pt\n",
      "Optimizer: Adam\n",
      "Epoch 1     loss=0.5114 [91.9 s]    dev=(HR@5:0.0559,NDCG@5:0.0399) [26.4 s] *\n",
      "Epoch 2     loss=0.3739 [92.3 s]    dev=(HR@5:0.0715,NDCG@5:0.0495) [24.9 s] *\n",
      "Epoch 3     loss=0.3370 [93.0 s]    dev=(HR@5:0.0814,NDCG@5:0.0561) [25.2 s] *\n",
      "Epoch 4     loss=0.3148 [95.2 s]    dev=(HR@5:0.0835,NDCG@5:0.0573) [25.0 s] *\n",
      "Epoch 5     loss=0.2968 [94.8 s]    dev=(HR@5:0.0854,NDCG@5:0.0584) [25.2 s] *\n",
      "Epoch 6     loss=0.2819 [94.5 s]    dev=(HR@5:0.0848,NDCG@5:0.0575) [25.4 s]\n",
      "Epoch 7     loss=0.2688 [94.3 s]    dev=(HR@5:0.0858,NDCG@5:0.0580) [25.3 s]\n",
      "Epoch 8     loss=0.2558 [93.4 s]    dev=(HR@5:0.0853,NDCG@5:0.0575) [25.1 s]\n",
      "Epoch 9     loss=0.2459 [96.4 s]    dev=(HR@5:0.0856,NDCG@5:0.0577) [25.2 s]\n",
      "Epoch 10    loss=0.2352 [96.3 s]    dev=(HR@5:0.0837,NDCG@5:0.0571) [25.6 s]\n",
      "\n",
      "Best Iter(dev)=    5\t dev=(HR@5:0.0854,NDCG@5:0.0584) [1196.0 s] \n",
      "Load model from ../model/Chorus/Chorus__ta_feng__3500__average__lr=0.001__l2=0__margin=1__lr_scale=0.1__stage=2.pt\n",
      "\n",
      "Test After Training: (HR@5:0.0944,NDCG@5:0.0648,HR@10:0.1312,NDCG@10:0.0767,HR@15:0.1551,NDCG@15:0.0830)\n",
      "\n",
      "--------------------------------------------- END: 2022-06-04 15:13:30 ---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "run_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Yandex DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "2c5d6e00-a3f0-4eec-900b-ccbee64380ae",
  "notebookPath": "ReChorus/src/[upd] exp_ta_feng.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
